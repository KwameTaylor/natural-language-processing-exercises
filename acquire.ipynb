{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition Web Scraping Exercises\n",
    "### Kwame V. Taylor\n",
    "\n",
    "By the end of this exercise, you should have a file named ```acquire.py``` that contains the specified functions. If you wish, you may break your work into separate files for each website (e.g. ```acquire_codeup_blog.py``` and ```acquire_news_articles.py```), but the end function should be present in ```acquire.py``` (that is, ```acquire.py``` should import ```get_blog_articles``` from the ```acquire_codeup_blog``` module.)\n",
    "\n",
    "1. **Codeup Blog Articles**\n",
    "\n",
    "Scrape the article text from the following pages:\n",
    "\n",
    "* https://codeup.com/codeups-data-science-career-accelerator-is-here/\n",
    "* https://codeup.com/data-science-myths/\n",
    "* https://codeup.com/data-science-vs-data-analytics-whats-the-difference/\n",
    "* https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/\n",
    "* https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/\n",
    "\n",
    "Encapsulate your work in a function named ```get_blog_articles``` that will return a list of dictionaries, with each dictionary representing one article. The shape of each dictionary should look like this:\n",
    "\n",
    ">```\n",
    ">{\n",
    ">    'title': 'the title of the article',\n",
    ">    'content': 'the full text content of the article'\n",
    ">}\n",
    ">```\n",
    "\n",
    "Plus any additional properties you think might be helpful.\n",
    "\n",
    "**Bonus:**\n",
    "Scrape the text of all the articles linked on codeup's blog page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from requests import get\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} # Some websites don't accept the pyhon-requests default user-agent\n",
    "response = get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html><html lang=\"en-US\"><head >\t<meta charset=\"UTF-8\" />\n",
      "\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n",
      "\t<style type=\"text/css\" id=\"nab-alternative-loader-style\"></style>\n",
      "<script type=\"text/javascript\" id=\"nelio-ab-testing-kickoff\">/* <![CDATA[ */( function() { var ua = window.navigator.userAgent || ''; if ( -1 !== ua.indexOf( 'MSIE ' ) || -1 !== ua.indexOf( 'Tri\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a soup variable holding the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('h1').text\n",
    "content = soup.find('p').text\n",
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blog_articles(urls):\n",
    "    articles = []\n",
    "\n",
    "    for url in urls:\n",
    "        # Make request and soup object\n",
    "        headers = {'User-Agent': 'Codeup Data Science'} \n",
    "        response = get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # get title and paragraph/content\n",
    "        title = soup.find('h1').text\n",
    "        content = soup.find('p').text\n",
    "\n",
    "        # store articles\n",
    "        article = {'title': title, 'content': content}\n",
    "        articles.append(article)\n",
    "            \n",
    "    # save as a DataFrame\n",
    "    df = pd.DataFrame(articles)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Codeup’s Data Science Career Accelerator is Here!</td>\n",
       "      <td>The rumors are true! The time has arrived. Cod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Myths</td>\n",
       "      <td>By Dimitri Antoniou and Maggie Giust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science VS Data Analytics: What’s The Dif...</td>\n",
       "      <td>By Dimitri Antoniou</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10 Tips to Crush It at the SA Tech Job Fair</td>\n",
       "      <td>The third bi-annual San Antonio Tech Job Fair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Competitor Bootcamps Are Closing. Is the Model...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Codeup’s Data Science Career Accelerator is Here!   \n",
       "1                                 Data Science Myths   \n",
       "2  Data Science VS Data Analytics: What’s The Dif...   \n",
       "3        10 Tips to Crush It at the SA Tech Job Fair   \n",
       "4  Competitor Bootcamps Are Closing. Is the Model...   \n",
       "\n",
       "                                             content  \n",
       "0  The rumors are true! The time has arrived. Cod...  \n",
       "1               By Dimitri Antoniou and Maggie Giust  \n",
       "2                                By Dimitri Antoniou  \n",
       "3  The third bi-annual San Antonio Tech Job Fair ...  \n",
       "4                                                     "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = get_blog_articles(['https://codeup.com/codeups-data-science-career-accelerator-is-here/',\n",
    "        'https://codeup.com/data-science-myths/',\n",
    "        'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/',\n",
    "        'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/',\n",
    "        'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **News Articles**\n",
    "\n",
    "We will now be scraping text data from inshorts, a website that provides a brief overview of many different topics.\n",
    "\n",
    "Write a function that scrapes the news articles for the following topics:\n",
    "\n",
    "* Business\n",
    "* Sports\n",
    "* Technology\n",
    "* Entertainment\n",
    "\n",
    "The end product of this should be a function named ```get_news_articles``` that returns a list of dictionaries, where each dictionary has this shape:\n",
    "\n",
    ">```\n",
    ">{\n",
    ">    'title': 'The article title',\n",
    ">    'content': 'The article content',\n",
    ">    'category': 'business' # for example\n",
    ">}\n",
    ">```\n",
    "\n",
    "Hints:\n",
    "\n",
    "a. Start by inspecting the website in your browser. Figure out which elements will be useful.\n",
    "\n",
    "b. Start by creating a function that handles a single article and produces a dictionary like the one above.\n",
    "\n",
    "c. Next create a function that will find all the articles on a single page and call the function you created in the last step for every article on the page.\n",
    "\n",
    "d. Now create a function that will use the previous two functions to scrape the articles from all the pages that you need, and do any additional processing that needs to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think h1 and h2 will be helpful info to scrap.\n",
    "# The navigation links are in div, and start with 'action_links'\n",
    "\n",
    "#def get_article(url):\n",
    "url = 'https://inshorts.com/en/read/business'\n",
    "headers = {'User-Agent': 'Codeup Data Science'} # Some websites don't accept the pyhon-requests default user-agent\n",
    "response = get(url, headers=headers)\n",
    "#    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=\"en\">\n",
      "\n",
      "<head>\n",
      "  <meta charset=\"utf-8\" />\n",
      "  <style>\n",
      "    /* The Modal (background) */\n",
      "    .modal_contact {\n",
      "        display: none; /* Hidden by default */\n",
      "        position: fixed; /* Stay in place */\n",
      "        z-index: 8; /* Sit on top */\n",
      "        left: 0;\n",
      "        top: 0;\n",
      "        width: 100%; /* Full width */\n",
      "        height: 100%;\n",
      "        overflow: auto; /* Enable scroll if ne\n"
     ]
    }
   ],
   "source": [
    "print(response.text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.BeautifulSoup'>\n"
     ]
    }
   ],
   "source": [
    "# Make a soup variable holding the response content\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "print(type(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'toggle menu'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = soup.find('span').text\n",
    "content = soup.find('content')\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_articles():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_articles(urls):\n",
    "    articles = []\n",
    "\n",
    "    for url in urls:\n",
    "        # Make request and soup object\n",
    "        headers = {'User-Agent': 'Codeup Data Science'} \n",
    "        response = get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # get title and paragraph/content\n",
    "        title = soup.find('h1').text\n",
    "        content = soup.find('p').text\n",
    "\n",
    "        # store articles\n",
    "        article = {'title': title, 'content': content}\n",
    "        articles.append(article)\n",
    "            \n",
    "    # save as a DataFrame\n",
    "    df = pd.DataFrame(articles)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-0c5dbeb5fb44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = get_news_articles(['https://inshorts.com/en/read/business',\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m'https://inshorts.com/en/read/sports'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m'https://inshorts.com/en/read/technology'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         'https://inshorts.com/en/read/entertainment'])\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-41c7501abb16>\u001b[0m in \u001b[0;36mget_news_articles\u001b[0;34m(urls)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# get title and paragraph/content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mtitle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "df = get_news_articles(['https://inshorts.com/en/read/business',\n",
    "        'https://inshorts.com/en/read/sports',\n",
    "        'https://inshorts.com/en/read/technology',\n",
    "        'https://inshorts.com/en/read/entertainment'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
